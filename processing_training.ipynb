{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\" Training script to input data and train model\n",
    "\n",
    "This module is use for procssing training. The input function is in \n",
    "converter_generator modeule. The model is in model modeule. The optimizer is in\n",
    "optimizer modeule.\n",
    "\n",
    "################################################################################\n",
    "# Author: Weikun Han <weikunhan@gmail.com>\n",
    "# Crate Date: 03/10/2018        \n",
    "# Update:\n",
    "# Reference: https://github.com/jhetherly/EnglishSpeechUpsampler\n",
    "################################################################################\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from converter_generator import bitrates_and_waveforms\n",
    "from converter_generator import get_original_noise_pairs\n",
    "from converter_generator import next_batch\n",
    "from converter_generator import random_batch\n",
    "from model import audio_u_net_dnn\n",
    "from optimizer import setup_optimizer\n",
    "from optimizer import learing_rate_scheduling\n",
    "\n",
    "# Please modify input path  to locate you file\n",
    "DATASETS_ROOT_DIR = './datasets'\n",
    "FILE_NAME_LISTS_DIR = os.path.join(DATASETS_ROOT_DIR, 'final_dataset')\n",
    "\n",
    "# Please modify setting for training\n",
    "n_epochs = 10\n",
    "batch_size = 8\n",
    "initial_learning_rate = 0.001\n",
    "learning_rate_decay_factor = 0.01\n",
    "n_epochs_per_decay = 2\n",
    "\n",
    "#############\n",
    "# DATA IMPORT\n",
    "#############\n",
    "\n",
    "train_original_noise_pairs = get_original_noise_pairs(FILE_NAME_LISTS_DIR,\n",
    "                                                      'train')\n",
    "val_original_noise_pairs = get_original_noise_pairs(file_name_lists_dir,\n",
    "                                                    'validation')\n",
    "\n",
    "# Selet first original noise pair, return first is bit rate pair and second\n",
    "# is the waveform pair\n",
    "br_pair, wf_pair = bitrates_and_waveforms(train_original_noise_pairs[0])\n",
    "\n",
    "# Get original bit rate and waveform\n",
    "original_bitrate = br_pair[0]\n",
    "original_waveform = wf_pair[0]\n",
    "\n",
    "# reshape for mono waveforms\n",
    "original_waveform = original_waveform.reshape((-1, 1))\n",
    "\n",
    "# Number of sample for each epoch train\n",
    "sample_per_epoch = len(train_original_noise_pairs)\n",
    "\n",
    "print('Number of epochs: {}'.format(n_epochs))\n",
    "print('Samples per epoch: {}'.format(sample_per_epoch))\n",
    "print('Batch size: {}'.format(batch_size))\n",
    "print('-------------------------Processing training---------------------------')\n",
    "\n",
    "##################\n",
    "# MODEL DEFINITION\n",
    "##################\n",
    "\n",
    "train_flag, x, y_pred = audio_u_net_dnn(original_waveform.dtype,\n",
    "                                        original_waveform.shape)\n",
    "\n",
    "# placeholder for the true waveform\n",
    "y = tf.placeholder(original_waveform.dtype,\n",
    "                   shape=x.get_shape(),\n",
    "                   name='y')\n",
    "\n",
    "# #############\n",
    "# LOSS FUNCTION\n",
    "# #############\n",
    "\n",
    "mse = tf.reduce_mean(tf.square(tf.subtract(y_pred, y)), name='mse')\n",
    "tf.summary.scalar('MSE', mse)\n",
    "\n",
    "# TODO\n",
    "# ####################\n",
    "# OPTIMIZATION ROUTINE\n",
    "# ####################\n",
    "\n",
    "# Variable that affect learning rate.\n",
    "num_batches_per_epoch = float(SAMPLES_PER_EPOCH)/BATCH_SIZE\n",
    "decay_steps = int(num_batches_per_epoch * NUM_EPOCHS_PER_DECAY)\n",
    "\n",
    "# Decay the learning rate based on the number of steps.\n",
    "lr, global_step = make_variable_learning_rate(INITIAL_LEARNING_RATE,\n",
    "                                              decay_steps,\n",
    "                                              LEARNING_RATE_DECAY_FACTOR,\n",
    "                                              False)\n",
    "\n",
    "# lr = 1e-4\n",
    "# min_args = {}\n",
    "min_args = {'global_step': global_step}\n",
    "training_op = setup_optimizer(lr, mse, tf.train.AdamOptimizer,\n",
    "                              using_batch_norm=True,\n",
    "                              min_args=min_args)\n",
    "\n",
    "##################\n",
    "# TRAINING PROCESS\n",
    "##################\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# initialize tensorboard file writers\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter('/tensorboard', tf.get_default_graph())\n",
    "\n",
    "# initialize the variables for the session\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    model_name = y_pred.name.replace('/', '_').replace(':', '_')\n",
    "    val_loss_file = open('val_loss_log.txt', 'w')\n",
    "    train_loss_file = open('train_loss_log.txt', 'w')\n",
    "\n",
    "    # The number of batchs in each epoch train\n",
    "    n_batchs = int(sample_per_epoch / batch_size)\n",
    "\n",
    "    # The number of iteration\n",
    "    n_iterations = n_epochs * n_batchs\n",
    "\n",
    "    # Start train loop\n",
    "    for i in range(n_iterations):\n",
    "\n",
    "        # Setting a flag to cheack iteration go to next epoch\n",
    "        new_epoch_flag = ((i + 1) % n_batchs == 0)\n",
    "\n",
    "        # Record epoch number\n",
    "        if new_epoch_flag:\n",
    "            epoch_number = int((i + 1) / n_batchs)\n",
    "\n",
    "        # Start validation if enter new epoch\n",
    "        if new_epoch_flag:\n",
    "\n",
    "            print('Calculating validation loss by total {} iterations'.format(\n",
    "                len(val_original_noise_pairs) / batch_size))\n",
    "\n",
    "            total_val_loss = 0\n",
    "            val_count = 0\n",
    "\n",
    "            # Find each validation loss for same batch size\n",
    "            for val_batch in next_batch(batch_size, val_original_noise_pairs):\n",
    "                loss = sess.run([mse],\n",
    "                                feed_dict={train_flag: False,\n",
    "                                           x: val_batch[1],\n",
    "                                           y: val_batch[0]})\n",
    "                total_val_loss += np.mean(loss)\n",
    "                val_count += 1\n",
    "\n",
    "            # Calculate the the average validaton loss\n",
    "            val_loss = total_val_loss / val_count\n",
    "\n",
    "            print(\"Epoch is: {}, Validation Loss is: {}\".format(epoch_number, \n",
    "                                                                val_loss))\n",
    "            \n",
    "            # Record the average validation loss for each epoch\n",
    "            val_loss_file.write('Epoch is: {}, Validation Loss is:{}\\n'.format(\n",
    "                epoch_number, val_loss))\n",
    "\n",
    "        print('The training iterations is: {}'.format(i))\n",
    "\n",
    "        # Random generate next batch in the training file\n",
    "        train_batch = random_batch(batch_size, train_original_noise_pairs)\n",
    "\n",
    "        # Start recording traning loss if enter a new epoch\n",
    "        if new_epoch_flag:\n",
    "            summary, _, train_loss = sess.run([merged, training_op, mse],\n",
    "                                              feed_dict={train_flag: True,\n",
    "                                                         x: batch[1],\n",
    "                                                         y: batch[0]})\n",
    "                \n",
    "            print(\"Epoch is: {}, Training Loss is: {}\".format(epoch_number, \n",
    "                                                              train_loss))\n",
    "                \n",
    "            train_writer.add_summary(summary, i)\n",
    "                \n",
    "            # Record the training loss for each epoch\n",
    "            train_loss_file.write(\n",
    "                'Epoch is: {}, Training Loss is: {}\\n'.format(epoch_number, \n",
    "                                                              train_loss))\n",
    "                \n",
    "            # Store the training model every 3 epoch\n",
    "            if epoch_number % 3 == 0:\n",
    "                save_path = saver.save(\n",
    "                    sess, \"model_checkpoints/{}_{}.ckpt\".format(model_name, \n",
    "                                                                epoch_number))\n",
    "\n",
    "        # Run tensorflow for each train batch\n",
    "        sess.run(training_op, \n",
    "                 feed_dict={train_flag: True,\n",
    "                            x: train_batch[1],\n",
    "                            y: train_batch[0]})\n",
    "\n",
    "    val_loss_file.close()\n",
    "    train_loss_file.close()\n",
    "\n",
    "    # Save the variables to disk.\n",
    "    save_path = saver.save(sess, \n",
    "                           \"model_checkpoints/{}_final.ckpt\".format(model_name))\n",
    "\n",
    "print(\"Model checkpoints will be saved in file: {}\".format(save_path))\n",
    "print('------------------------Finished model training------------------------')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "truth, example = read_file_pair(val_truth_ds_pairs[1])\n",
    "y_reco = model.eval(feed_dict={train_flag: False,\n",
    "                               x: example.reshape(1, -1, 1)},\n",
    "                    session=sess).flatten()\n",
    "\n",
    "print('difference between truth and example (first 20 elements)')\n",
    "print(truth.flatten()[:20] - example.flatten()[:20])\n",
    "print('difference between truth and reconstruction (first 20 elements)')\n",
    "print(truth.flatten()[:20] - y_reco[:20])\n",
    "\n",
    "print('writting output audio files')\n",
    "librosa.output.write_wav('full_train_validation_true.wav',\n",
    "                         y=truth.flatten(), sr=true_br)\n",
    "librosa.output.write_wav('full_train_validation_ds.wav',\n",
    "                         y=example.flatten(), sr=true_br)\n",
    "librosa.output.write_wav('full_train_validation_reco.wav',\n",
    "                         y=y_reco, sr=true_br)\n",
    "                         \n",
    "\"\"\"\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
