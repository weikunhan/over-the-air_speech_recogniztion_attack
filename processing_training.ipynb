{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The script to train the deep neural networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module can use for processing training. You need modify the number of epochs you want, the size of batch, the initial learning rate, the devay factor for changing learning rate, and number of epochs to decay learning rate. And you can modify output directory you want and input directory you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------Begining data input---------------------------\n",
      "Number of epochs: 10\n",
      "Samples per epoch: 814\n",
      "Batch size: 8\n",
      "-------------------------Processing training---------------------------\n",
      "The network summary for audio_u_net_dnn\n",
      "    input: [None, 80000, 1]\n",
      "    downsample layer: [None, 39998, 8]\n",
      "    downsample layer: [None, 19998, 16]\n",
      "    downsample layer: [None, 9998, 32]\n",
      "    downsample layer: [None, 4998, 64]\n",
      "    downsample layer: [None, 2498, 128]\n",
      "    downsample layer: [None, 1248, 256]\n",
      "    downsample layer: [None, 623, 512]\n",
      "    downsample layer: [None, 311, 1024]\n",
      "    bottleneck layer: [None, 154, 2048]\n",
      "    upsample layer: [None, 304, 2048]\n",
      "    upsample layer: [None, 604, 1024]\n",
      "    upsample layer: [None, 1204, 512]\n",
      "    upsample layer: [None, 2404, 256]\n",
      "    upsample layer: [None, 4804, 128]\n",
      "    upsample layer: [None, 9604, 64]\n",
      "    upsample layer: [None, 19204, 32]\n",
      "    upsample layer: [None, 38404, 16]\n",
      "    restack layer: [None, 40002, 15]\n",
      "    final convolution layer: [None, 40000, 2]\n",
      "    output: [None, 80000, 1]\n",
      "--------------------Finished model building--------------------\n",
      "The training iterations is: 0\n",
      "The training iterations is: 1\n",
      "The training iterations is: 2\n",
      "The training iterations is: 3\n",
      "The training iterations is: 4\n",
      "The training iterations is: 5\n",
      "The training iterations is: 6\n",
      "The training iterations is: 7\n",
      "The training iterations is: 8\n",
      "The training iterations is: 9\n",
      "The training iterations is: 10\n",
      "The training iterations is: 11\n",
      "The training iterations is: 12\n",
      "The training iterations is: 13\n",
      "The training iterations is: 14\n",
      "The training iterations is: 15\n",
      "The training iterations is: 16\n",
      "The training iterations is: 17\n",
      "The training iterations is: 18\n",
      "The training iterations is: 19\n",
      "The training iterations is: 20\n",
      "The training iterations is: 21\n",
      "The training iterations is: 22\n",
      "The training iterations is: 23\n",
      "The training iterations is: 24\n",
      "The training iterations is: 25\n",
      "The training iterations is: 26\n",
      "The training iterations is: 27\n",
      "The training iterations is: 28\n",
      "The training iterations is: 29\n",
      "The training iterations is: 30\n",
      "The training iterations is: 31\n",
      "The training iterations is: 32\n",
      "The training iterations is: 33\n",
      "The training iterations is: 34\n",
      "The training iterations is: 35\n",
      "The training iterations is: 36\n",
      "The training iterations is: 37\n",
      "The training iterations is: 38\n",
      "The training iterations is: 39\n",
      "The training iterations is: 40\n",
      "The training iterations is: 41\n",
      "The training iterations is: 42\n",
      "The training iterations is: 43\n",
      "The training iterations is: 44\n",
      "The training iterations is: 45\n",
      "The training iterations is: 46\n",
      "The training iterations is: 47\n",
      "The training iterations is: 48\n",
      "The training iterations is: 49\n",
      "The training iterations is: 50\n",
      "The training iterations is: 51\n",
      "The training iterations is: 52\n",
      "The training iterations is: 53\n",
      "The training iterations is: 54\n",
      "The training iterations is: 55\n",
      "The training iterations is: 56\n",
      "The training iterations is: 57\n",
      "The training iterations is: 58\n",
      "The training iterations is: 59\n",
      "The training iterations is: 60\n",
      "The training iterations is: 61\n",
      "The training iterations is: 62\n",
      "The training iterations is: 63\n",
      "The training iterations is: 64\n",
      "The training iterations is: 65\n",
      "The training iterations is: 66\n",
      "The training iterations is: 67\n",
      "The training iterations is: 68\n",
      "The training iterations is: 69\n",
      "The training iterations is: 70\n",
      "The training iterations is: 71\n",
      "The training iterations is: 72\n",
      "The training iterations is: 73\n",
      "The training iterations is: 74\n",
      "The training iterations is: 75\n",
      "The training iterations is: 76\n",
      "The training iterations is: 77\n",
      "The training iterations is: 78\n",
      "The training iterations is: 79\n",
      "The training iterations is: 80\n",
      "The training iterations is: 81\n",
      "The training iterations is: 82\n",
      "The training iterations is: 83\n",
      "The training iterations is: 84\n",
      "The training iterations is: 85\n",
      "The training iterations is: 86\n",
      "The training iterations is: 87\n",
      "The training iterations is: 88\n",
      "The training iterations is: 89\n",
      "The training iterations is: 90\n",
      "The training iterations is: 91\n",
      "The training iterations is: 92\n",
      "The training iterations is: 93\n",
      "The training iterations is: 94\n",
      "The training iterations is: 95\n",
      "The training iterations is: 96\n",
      "The training iterations is: 97\n",
      "The training iterations is: 98\n",
      "The training iterations is: 99\n",
      "The training iterations is: 100\n",
      "Calculating validation loss by total 20.25 iterations\n",
      "Epoch is: 1, Validation Loss is: 0.006058866002907355\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'audio_u_net_dnn_1/Placeholder' with dtype bool\n\t [[Node: audio_u_net_dnn_1/Placeholder = Placeholder[dtype=DT_BOOL, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'audio_u_net_dnn_1/Placeholder', defined at:\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-d35328a1f840>\", line 83, in <module>\n    original_waveform.shape)\n  File \"/Users/WeikunHan/Documents/GitHub/Weikun-Zhengshuang/model.py\", line 593, in audio_u_net_dnn\n    train_flag = tf.placeholder(tf.bool)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1680, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3141, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'audio_u_net_dnn_1/Placeholder' with dtype bool\n\t [[Node: audio_u_net_dnn_1/Placeholder = Placeholder[dtype=DT_BOOL, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'audio_u_net_dnn_1/Placeholder' with dtype bool\n\t [[Node: audio_u_net_dnn_1/Placeholder = Placeholder[dtype=DT_BOOL, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d35328a1f840>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    193\u001b[0m                                               feed_dict={train_flag: True,\n\u001b[1;32m    194\u001b[0m                                                          \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                                                          y: train_batch[0]})\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             print('Epoch is: {}, Training Loss is: {}'.format(epoch_number, \n",
      "\u001b[0;32m~/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1363\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1365\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'audio_u_net_dnn_1/Placeholder' with dtype bool\n\t [[Node: audio_u_net_dnn_1/Placeholder = Placeholder[dtype=DT_BOOL, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'audio_u_net_dnn_1/Placeholder', defined at:\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-d35328a1f840>\", line 83, in <module>\n    original_waveform.shape)\n  File \"/Users/WeikunHan/Documents/GitHub/Weikun-Zhengshuang/model.py\", line 593, in audio_u_net_dnn\n    train_flag = tf.placeholder(tf.bool)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1680, in placeholder\n    return gen_array_ops._placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3141, in _placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\n    op_def=op_def)\n  File \"/Users/WeikunHan/anaconda3/envs/over-the-air_SRA/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'audio_u_net_dnn_1/Placeholder' with dtype bool\n\t [[Node: audio_u_net_dnn_1/Placeholder = Placeholder[dtype=DT_BOOL, shape=<unknown>, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\" The script to train the deep neural networks\n",
    "\n",
    "This module can use for processing training. You need modify the number of \n",
    "epochs you want, the size of batch, the initial learning rate, the devay factor \n",
    "for changing learning rate, and number of epochs to decay learning rate. And you \n",
    "can modify output directory you want and input directory you have.\n",
    "\n",
    "################################################################################\n",
    "# Author: Weikun Han <weikunhan@gmail.com>\n",
    "# Crate Date: 03/10/2018        \n",
    "# Update:\n",
    "# Reference: https://github.com/jhetherly/EnglishSpeechUpsampler\n",
    "################################################################################\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from converter_generator import bitrates_and_waveforms\n",
    "from converter_generator import get_original_noise_pairs\n",
    "from converter_generator import next_batch\n",
    "from converter_generator import random_batch\n",
    "from model import audio_u_net_dnn\n",
    "from optimizer import setup_optimizer\n",
    "from optimizer import learing_rate_scheduling\n",
    "\n",
    "# Please modify input path  to locate you file\n",
    "DATASETS_ROOT_DIR = './datasets'\n",
    "FILE_NAME_LISTS_DIR = os.path.join(DATASETS_ROOT_DIR, 'final_dataset')\n",
    "OUTPUT_TENSORBOARD_DIR = './output'\n",
    "OUTPUT_MODEL_DIR = './output/model'\n",
    "\n",
    "# Please modify setting for training\n",
    "n_epochs = 10\n",
    "batch_size = 8\n",
    "initial_learning_rate = 0.001\n",
    "decay_factor = 0.01\n",
    "n_epochs_per_decay = 2\n",
    "\n",
    "# Check location to save datasets\n",
    "if not os.path.exists(OUTPUT_TENSORBOARD_DIR):\n",
    "    os.makedirs(OUTPUT_TENSORBOARD_DIR)\n",
    "if not os.path.exists(OUTPUT_MODEL_DIR):\n",
    "    os.makedirs(OUTPUT_MODEL_DIR)\n",
    "\n",
    "print('-------------------------Begining data input---------------------------')\n",
    "\n",
    "#############\n",
    "# DATA IMPORT\n",
    "#############\n",
    "\n",
    "train_original_noise_pairs = get_original_noise_pairs(FILE_NAME_LISTS_DIR,\n",
    "                                                      'train')\n",
    "val_original_noise_pairs = get_original_noise_pairs(FILE_NAME_LISTS_DIR,\n",
    "                                                    'validation')\n",
    "\n",
    "# Selet first original noise pair, return first is bit rate pair and second\n",
    "# is the waveform pair\n",
    "br_pair, wf_pair = bitrates_and_waveforms(train_original_noise_pairs[0])\n",
    "\n",
    "# Get original bit rate and waveform\n",
    "original_bitrate = br_pair[0]\n",
    "original_waveform = wf_pair[0]\n",
    "\n",
    "# reshape for mono waveforms\n",
    "original_waveform = original_waveform.reshape((-1, 1))\n",
    "\n",
    "# Number of sample for each epoch train\n",
    "sample_per_epoch = len(train_original_noise_pairs)\n",
    "\n",
    "print('Number of epochs: {}'.format(n_epochs))\n",
    "print('Samples per epoch: {}'.format(sample_per_epoch))\n",
    "print('Batch size: {}'.format(batch_size))\n",
    "print('-------------------------Processing training---------------------------')\n",
    "\n",
    "##################\n",
    "# MODEL DEFINITION\n",
    "##################\n",
    "\n",
    "train_flag, x, y_pred = audio_u_net_dnn(original_waveform.dtype,\n",
    "                                        original_waveform.shape)\n",
    "\n",
    "# placeholder for the true waveform\n",
    "y = tf.placeholder(original_waveform.dtype,\n",
    "                   shape=x.get_shape(),\n",
    "                   name='y')\n",
    "\n",
    "###############\n",
    "# LOSS FUNCTION\n",
    "###############\n",
    "\n",
    "with tf.name_scope('mse'):\n",
    "    mse = tf.reduce_mean(tf.square(tf.subtract(y_pred, y)))\n",
    "\n",
    "tf.summary.scalar('mse', mse)\n",
    "\n",
    "######################\n",
    "# OPTIMIZATION ROUTINE\n",
    "######################\n",
    "\n",
    "# Variable that affect learning rate.\n",
    "n_batches_per_epoch = float(sample_per_epoch)/ batch_size\n",
    "decay_steps = int(n_batches_per_epoch * n_epochs_per_decay)\n",
    "\n",
    "# Decay the learning rate based on the number of steps.\n",
    "learning_rate, global_step = learing_rate_scheduling(initial_learning_rate,\n",
    "                                                     decay_steps,\n",
    "                                                     decay_factor)\n",
    "\n",
    "# Setup the training operator\n",
    "min_args = {'global_step': global_step}\n",
    "training_op = setup_optimizer(learning_rate,\n",
    "                              mse,\n",
    "                              tf.train.AdamOptimizer,\n",
    "                              minimize_args=min_args)\n",
    "\n",
    "##################\n",
    "# TRAINING PROCESS\n",
    "##################\n",
    "\n",
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# initialize the variables for the session\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    # initialize tensorboard file writers\n",
    "    merged = tf.summary.merge_all()\n",
    "    tensorboard_path = os.path.join(OUTPUT_TENSORBOARD_DIR, 'tensorboard')\n",
    "    train_writer = tf.summary.FileWriter(tensorboard_path, sess.graph)\n",
    "    model_name = y_pred.name[: 15]\n",
    "    val_loss_file = open('val_loss_log.txt', 'w')\n",
    "    train_loss_file = open('train_loss_log.txt', 'w')\n",
    "\n",
    "    # The number of batchs in each epoch train\n",
    "    n_batchs = int(sample_per_epoch / batch_size)\n",
    "\n",
    "    # The number of iteration\n",
    "    n_iterations = n_epochs * n_batchs\n",
    "\n",
    "    # Start train loop\n",
    "    for i in range(n_iterations):\n",
    "        \n",
    "        print('The training iterations is: {}'.format(i))\n",
    "        \n",
    "        # Random generate next batch in the training file\n",
    "        train_batch = random_batch(batch_size, train_original_noise_pairs)\n",
    "\n",
    "        # Setting a flag to cheack iteration go to next epoch\n",
    "        new_epoch_flag = ((i + 1) % n_batchs == 0)\n",
    "\n",
    "        # Record epoch number\n",
    "        if new_epoch_flag:\n",
    "            epoch_number = int((i + 1) / n_batchs)\n",
    "\n",
    "        # Start validation if enter new epoch\n",
    "        if new_epoch_flag:\n",
    "\n",
    "            print('Calculating validation loss by total {} iterations'.format(\n",
    "                len(val_original_noise_pairs) / batch_size))\n",
    "\n",
    "            total_val_loss = 0\n",
    "            val_count = 0\n",
    "\n",
    "            # Find each validation loss for same batch size\n",
    "            for val_batch in next_batch(batch_size, val_original_noise_pairs):\n",
    "                loss = sess.run([mse],\n",
    "                                feed_dict={train_flag: False,\n",
    "                                           x: val_batch[1],\n",
    "                                           y: val_batch[0]})\n",
    "                total_val_loss += np.mean(loss)\n",
    "                val_count += 1\n",
    "\n",
    "            # Calculate the the average validaton loss\n",
    "            val_loss = total_val_loss / val_count\n",
    "\n",
    "            print('Epoch is: {}, Validation Loss is: {}'.format(epoch_number, \n",
    "                                                                val_loss))\n",
    "            \n",
    "            # Record the average validation loss for each epoch\n",
    "            val_loss_file.write(\n",
    "                'Epoch is: {}, Validation Loss is:{}\\n'.format(epoch_number, \n",
    "                                                               val_loss))\n",
    "\n",
    "        # Start recording traning loss if enter a new epoch\n",
    "        if new_epoch_flag:\n",
    "            summary, _, train_loss = sess.run([merged, training_op, mse],\n",
    "                                              feed_dict={train_flag: True,\n",
    "                                                         x: train_batch[1],\n",
    "                                                         y: train_batch[0]})\n",
    "                \n",
    "            print('Epoch is: {}, Training Loss is: {}'.format(epoch_number, \n",
    "                                                              train_loss))\n",
    "                \n",
    "            train_writer.add_summary(summary, i)\n",
    "                \n",
    "            # Record the training loss for each epoch\n",
    "            train_loss_file.write(\n",
    "                'Epoch is: {}, Training Loss is: {}\\n'.format(epoch_number, \n",
    "                                                              train_loss))\n",
    "                \n",
    "            # Store the training model every 3 epoch\n",
    "            if epoch_number % 3 == 0:\n",
    "                model_path = os.path.join(\n",
    "                    OUTPUT_MODEL_DIR, '{}_{}.ckpt'.format(model_name, \n",
    "                                                          epoch_number))\n",
    "                save_path = saver.save(sess, model_path)\n",
    "\n",
    "        # Run tensorflow for each train batch\n",
    "        sess.run(training_op, \n",
    "                 feed_dict={train_flag: True,\n",
    "                            x: train_batch[1],\n",
    "                            y: train_batch[0]})\n",
    "\n",
    "    val_loss_file.close()\n",
    "    train_loss_file.close()\n",
    "\n",
    "    # Save the variables to disk.\n",
    "    model_path = os.path.join(\n",
    "        OUTPUT_MODEL_DIR, '{}_final.ckpt'.format(model_name))\n",
    "    save_path = saver.save(sess, model_path)\n",
    "\n",
    "print(\"Model checkpoints will be saved in file: {}\".format(save_path))\n",
    "print('------------------------Finished model training------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
